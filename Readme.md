# NYC Taxi Trip Data Analysis

This project presents a comprehensive analysis and database design of the NYC Yellow Taxi trip dataset. It compares relational and document-based models (PostgreSQL & MongoDB), and applies data mining techniques including association rule mining and frequent itemset extraction.

---

## üì¶ Dataset Source & Description

- **Source**: NYC Taxi & Limousine Commission (TLC)  
- **Sample Size**: 44M+ trip records (reduced to ~1M for feasibility)  
- **Features**: Pickup/Dropoff times, locations, fare, tip, payment type, passenger count, rate code, vendor ID, etc.

---

## üß© Entity-Relationship (ER) Model

The ER model represents the high-level conceptual design of the dataset. It captures the key entities (`Trip`, `Vendor`, `Location`, `Payment`, `RateCode`, and `Time`) and their relationships.

### Highlights:
- `Trip` is the central entity linked to all others via FKs.
- `Time` is modeled as a weak entity for flexible date-time analysis.
- Lookup/reference tables like `Payment`, `Vendor`, `RateCode` promote normalization and consistency.

üìå **ER Diagram:**  
_![ER Diagram](INSERT_PATH_TO_ER_DIAGRAM.png)_

---

## üß± Relational Database Schema Design

### Key Design Goals:
- **Normalization** up to 3NF or BCNF
- Efficient for OLAP-style queries
- Avoid redundancy and anomalies

### Tables & Attributes:
- `Trip(ID, VendorID, PaymentID, RateCodeID, PickupLocationID, DropoffLocationID, PassengerCount, TripDistance, FareAmount, TipAmount, TotalAmount, ...)`
- `Time(TripID, PickupDate, PickupTime, DropoffDate, DropoffTime, DayOfWeek, IsWeekend)`
- `Location(ID, Borough, Zone)`
- `Vendor(ID, Description)`
- `Payment(ID, Description)`
- `RateCode(ID, Description)`

### Keys & Constraints:
- Surrogate `ID` keys for dimension tables
- Foreign key relationships with `ON DELETE CASCADE`
- Referential integrity enforced for joins and aggregations

üìÇ SQL Schema: [`Data_Import/table_creation.sql`](./Data_Import/table_creation.sql)

---

## üóÉÔ∏è Data Loading Instructions (SQL)

```bash
# Create tables
psql -U your_user -d your_db -f Data_Import/table_creation.sql

# Load data using COPY or pgAdmin
psql -U your_user -d your_db -f Data_Import/data_load.sql
```

---

## üìÑ Document-Oriented Model (MongoDB)

The document model embeds key information within a `trip` collection, where each document includes vendor, payment, location, and time data.

### Sample Document:
```json
{
  "trip_id": 12345,
  "vendor": "CMT",
  "pickup": {
    "datetime": "2023-02-01T10:30:00",
    "location": {
      "borough": "Manhattan",
      "zone": "Midtown Center"
    }
  },
  "dropoff": {
    "datetime": "2023-02-01T10:50:00",
    "location": {
      "borough": "Brooklyn",
      "zone": "Downtown Brooklyn"
    }
  },
  "fare": 20.5,
  "tip": 4.0,
  "payment_type": "Credit Card"
}
```

üìÇ MongoDB Script: [`MongoDB/trip_model.json`](./MongoDB/trip_model.json)

---

## üîç Query Examples & Performance Tuning

### PostgreSQL:
- Top 5 zones by average fare
- Average trip duration by day of week
- Most common payment types

### MongoDB:
- Aggregations using `$group`, `$project`, `$unwind`
- Geospatial queries on pickup zones

üìÇ SQL Queries: [`SQL_Queries/analysis_queries.sql`](./SQL_Queries/analysis_queries.sql)

---

## ‚ö° Indexing Strategy & Performance Benchmarks

### PostgreSQL:
- Indexes on `PickupLocationID`, `DropoffLocationID`, `PickupDate`, `PaymentID`
- B-Tree and composite indexes improved query times by ~40%

### MongoDB:
- Compound indexes on `pickup.datetime` + `pickup.location.zone`
- Performance monitored via `explain()` and `Atlas profiler`

üìÇ Benchmark Notebook: [`Benchmarks/index_tuning.ipynb`](./Benchmarks/index_tuning.ipynb)

---

## üîÑ Functional Dependencies & Normalization

- Ensured 3NF/BCNF: e.g.,  
  `Trip ‚Üí PaymentID`, `PaymentID ‚Üí PaymentType` ‚áí `Trip ‚Üí PaymentType`
- Avoided transitive and partial dependencies
- No derived or multivalued attributes in base schema

---

## üßπ Data Cleaning

- Removed nulls and outliers (`fare_amount <= 0`, unrealistic trip distances)
- Consolidated payment types (`Credit Card`, `CC` ‚Üí `Credit Card`)
- Added flags like `IsWeekend`, `RushHour` for analysis

üìÇ Cleaning Script: [`Data_Cleaning/cleaning_script.py`](./Data_Cleaning/cleaning_script.py)

---

## üõí Frequent Itemset Mining

Used Apriori to identify co-occurrence patterns between zones and payment types.

- Example: `{Zone=Midtown, Payment=Credit Card} ‚Üí Frequent set`
- Minimum support threshold: 0.03

üìÇ Notebook: [`Association_Mining/itemset_analysis.ipynb`](./Association_Mining/itemset_analysis.ipynb)

---

## üîó Association Rule Mining

Generated rules such as:

- `If PickupZone=Midtown ‚Üí likely DropoffZone=Downtown Brooklyn (confidence=0.72)`
- `If PaymentType=Cash ‚Üí shorter trip distance (confidence=0.61)`

üìÇ Notebook: [`Association_Mining/rule_mining.ipynb`](./Association_Mining/rule_mining.ipynb)

---

## üÜö Relational vs Document Database Justification

| Feature              | Relational (PostgreSQL)                     | Document (MongoDB)                        |
|----------------------|---------------------------------------------|-------------------------------------------|
| Normalization        | Fully normalized                           | Embedded & denormalized                  |
| Joins                | Native support with FK                     | Avoided by embedding                     |
| Query Flexibility    | High for complex, multi-table queries      | Great for hierarchical, nested data      |
| Performance          | Better for structured batch analysis       | Better for single document retrieval     |
| Storage              | More efficient due to normalization        | Redundant fields, higher space usage     |
| Use Case Fit         | Ideal for analytical OLAP queries          | Suitable for real-time app backends      |

---

## ‚ñ∂Ô∏è Execution Steps & Folder Structure

```bash
# Clone repo
git clone https://github.com/your-repo/nyc-taxi-analysis.git

# PostgreSQL setup
cd Data_Import
psql -U postgres -d nyc_taxi -f table_creation.sql
psql -U postgres -d nyc_taxi -f data_load.sql

# MongoDB setup
mongoimport --db nyc_taxi --collection trips --file MongoDB/trip_model.json --jsonArray
```

### üìÇ Folder Structure
```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Data_Import/
‚îÇ   ‚îú‚îÄ‚îÄ table_creation.sql
‚îÇ   ‚îî‚îÄ‚îÄ data_load.sql
‚îú‚îÄ‚îÄ SQL_Queries/
‚îÇ   ‚îî‚îÄ‚îÄ analysis_queries.sql
‚îú‚îÄ‚îÄ MongoDB/
‚îÇ   ‚îî‚îÄ‚îÄ trip_model.json
‚îú‚îÄ‚îÄ Benchmarks/
‚îÇ   ‚îî‚îÄ‚îÄ index_tuning.ipynb
‚îú‚îÄ‚îÄ Association_Mining/
‚îÇ   ‚îú‚îÄ‚îÄ itemset_analysis.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ rule_mining.ipynb
‚îú‚îÄ‚îÄ Data_Cleaning/
‚îÇ   ‚îî‚îÄ‚îÄ cleaning_script.py
‚îú‚îÄ‚îÄ Diagrams/
‚îÇ   ‚îî‚îÄ‚îÄ ER_Diagram.png
```

---

## üë®‚Äçüíª Author

Ashwin Kherde  
[LinkedIn](https://www.linkedin.com/in/ashwinkherde) ‚Ä¢ [GitHub](https://github.com/ashwinkherde)

---